{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1940,"sourceType":"datasetVersion","datasetId":1069}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import shap\nimport random\nimport pandas as pd\nimport numpy as np\nimport lime.lime_tabular\nfrom itertools import product\nimport matplotlib.pyplot as plt\n\nfrom keras.models import Model\nfrom keras.layers import Input, Dense\nfrom keras.optimizers import Adam\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import IsolationForest , RandomForestClassifier\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score , classification_report , ConfusionMatrixDisplay , roc_curve,auc , precision_recall_curve\nfrom lime.lime_tabular import LimeTabularExplainer\nfrom sklearn.inspection import PartialDependenceDisplay , permutation_importance","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/paysim1/PS_20174392719_1491204439457_log.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df['isFraud'].value_counts(normalize=True))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df.drop(columns=[\"nameOrig\", \"nameDest\"])\n\ndf[\"type\"] = LabelEncoder().fit_transform(df[\"type\"])\n\ny = df[\"isFraud\"]\nX = df.drop(columns=[\"isFraud\", \"isFlaggedFraud\"])\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **4 Scenarios Mentioned inside the Paper**","metadata":{}},{"cell_type":"markdown","source":"## **Scenario 1: Train/Test Split Optimization**\n* Try split ratios: 90:10, 80:20, 70:30, 60:40\n* Use full features, evaluate with AUCPR, ROC-AUC, Precision, Recall, F1","metadata":{}},{"cell_type":"code","source":"split_ratios = [(0.9, 0.1), (0.8, 0.2), (0.7, 0.3), (0.6, 0.4)]\n\nresults = []\n\nfor train_size, test_size in split_ratios:\n    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=test_size, stratify=y, random_state=42)\n\n    model = IsolationForest(n_estimators=100, max_samples=128, contamination=0.001, random_state=42)\n    model.fit(X_train)\n\n    y_pred = model.predict(X_test)\n    y_pred = [1 if x == -1 else 0 for x in y_pred]\n\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n    roc = roc_auc_score(y_test, y_pred)\n    \n    precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_pred)\n    aucpr = auc(recall_vals, precision_vals)\n\n    results.append((train_size, precision, recall, f1, roc, aucpr))\n\nfor r in results:\n    print(f\"Train Size: {int(r[0]*100)}% | Precision: {r[1]:.4f}, Recall: {r[2]:.4f}, F1: {r[3]:.4f}, ROC AUC: {r[4]:.4f}, AUCPR: {r[5]:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T10:11:21.967269Z","iopub.execute_input":"2025-05-01T10:11:21.967586Z","iopub.status.idle":"2025-05-01T10:24:33.487877Z","shell.execute_reply.started":"2025-05-01T10:11:21.967564Z","shell.execute_reply":"2025-05-01T10:24:33.486754Z"}},"outputs":[{"name":"stdout","text":"Train Size: 90% | Precision: 0.0069, Recall: 0.0049, F1: 0.0057, ROC AUC: 0.5020, AUCPR: 0.0065\nTrain Size: 80% | Precision: 0.0040, Recall: 0.0030, F1: 0.0035, ROC AUC: 0.5010, AUCPR: 0.0042\nTrain Size: 70% | Precision: 0.0011, Recall: 0.0008, F1: 0.0009, ROC AUC: 0.4999, AUCPR: 0.0016\nTrain Size: 60% | Precision: 0.0037, Recall: 0.0027, F1: 0.0031, ROC AUC: 0.5009, AUCPR: 0.0038\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"## **Scenario 2: Feature Selection**\n\n* Use Random Forest to select top N features (1â€“10)\n* Repeat Isolation Forest using top N features from Scenario 1 best split\n","metadata":{}},{"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=100, random_state=42)\nrf.fit(X_scaled, y)\nimportances = rf.feature_importances_\nfeature_ranks = np.argsort(importances)[::-1]\nfeatures_sorted = X.columns[feature_ranks]\n\nscenario2_results = []\n\nX_df = pd.DataFrame(X_scaled, columns=X.columns)\n\nfor n in range(1, 11):\n    top_features = features_sorted[:n]\n    X_selected = X_df[top_features]\n\n    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.4, stratify=y, random_state=42)\n\n    model = IsolationForest(n_estimators=100, max_samples=128, contamination=0.001, random_state=42)\n    model.fit(X_train)\n    y_pred = model.predict(X_test)\n    y_pred = [1 if x == -1 else 0 for x in y_pred]\n\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n    roc = roc_auc_score(y_test, y_pred)\n    precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_pred)\n    aucpr = auc(recall_vals, precision_vals)\n\n    scenario2_results.append((n, precision, recall, f1, roc, aucpr))\n\nfor res in scenario2_results:\n    print(f\"Top {res[0]} features | Precision: {res[1]:.4f}, Recall: {res[2]:.4f}, F1: {res[3]:.4f}, ROC AUC: {res[4]:.4f}, AUCPR: {res[5]:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T10:24:33.489475Z","iopub.execute_input":"2025-05-01T10:24:33.489778Z","iopub.status.idle":"2025-05-01T11:22:30.080970Z","shell.execute_reply.started":"2025-05-01T10:24:33.489755Z","shell.execute_reply":"2025-05-01T11:22:30.078275Z"}},"outputs":[{"name":"stderr","text":"X does not have valid feature names, but IsolationForest was fitted with feature names\nX does not have valid feature names, but IsolationForest was fitted with feature names\nX does not have valid feature names, but IsolationForest was fitted with feature names\nX does not have valid feature names, but IsolationForest was fitted with feature names\nX does not have valid feature names, but IsolationForest was fitted with feature names\nX does not have valid feature names, but IsolationForest was fitted with feature names\nX does not have valid feature names, but IsolationForest was fitted with feature names\nX does not have valid feature names, but IsolationForest was fitted with feature names\nX does not have valid feature names, but IsolationForest was fitted with feature names\nX does not have valid feature names, but IsolationForest was fitted with feature names\n","output_type":"stream"},{"name":"stdout","text":"Top 1 features | Precision: 0.0009, Recall: 0.0006, F1: 0.0007, ROC AUC: 0.4999, AUCPR: 0.0014\nTop 2 features | Precision: 0.0008, Recall: 0.0006, F1: 0.0007, ROC AUC: 0.4998, AUCPR: 0.0013\nTop 3 features | Precision: 0.0444, Recall: 0.0335, F1: 0.0382, ROC AUC: 0.5163, AUCPR: 0.0396\nTop 4 features | Precision: 0.0851, Recall: 0.0661, F1: 0.0744, ROC AUC: 0.5326, AUCPR: 0.0762\nTop 5 features | Precision: 0.0188, Recall: 0.0140, F1: 0.0160, ROC AUC: 0.5065, AUCPR: 0.0170\nTop 6 features | Precision: 0.0016, Recall: 0.0012, F1: 0.0014, ROC AUC: 0.5001, AUCPR: 0.0021\nTop 7 features | Precision: 0.0115, Recall: 0.0088, F1: 0.0100, ROC AUC: 0.5039, AUCPR: 0.0108\nTop 8 features | Precision: 0.0115, Recall: 0.0088, F1: 0.0100, ROC AUC: 0.5039, AUCPR: 0.0108\nTop 9 features | Precision: 0.0115, Recall: 0.0088, F1: 0.0100, ROC AUC: 0.5039, AUCPR: 0.0108\nTop 10 features | Precision: 0.0115, Recall: 0.0088, F1: 0.0100, ROC AUC: 0.5039, AUCPR: 0.0108\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## **Scenario 3: Fraud Ratio Variation**\n\n* Using best split + features\n* Vary the percentage of fraud samples used in training: 100%, 90%, ..., 5%\n","metadata":{}},{"cell_type":"code","source":"best_5 = features_sorted[:5]\nX_top5 = X_df[best_5]\n\nX_train_full, X_test, y_train_full, y_test = train_test_split(X_top5, y, test_size=0.4, stratify=y, random_state=42)\n\nX_train_fraud = X_train_full[y_train_full == 1]\nX_train_normal = X_train_full[y_train_full == 0]\n\nfraud_ratios = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.05]\nscenario3_results = []\n\nfor ratio in fraud_ratios:\n    n_fraud = int(len(X_train_fraud) * ratio)\n    X_train_combined = pd.concat([X_train_fraud.sample(n=n_fraud, random_state=42), X_train_normal])\n    \n    model = IsolationForest(n_estimators=100, max_samples=128, contamination=0.001, random_state=42)\n    model.fit(X_train_combined)\n    y_pred = model.predict(X_test)\n    y_pred = [1 if x == -1 else 0 for x in y_pred]\n\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n    roc = roc_auc_score(y_test, y_pred)\n    precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_pred)\n    aucpr = auc(recall_vals, precision_vals)\n\n    scenario3_results.append((ratio, precision, recall, f1, roc, aucpr))\n\nfor res in scenario3_results:\n    print(f\"Fraud %: {int(res[0]*100)} | Precision: {res[1]:.4f}, Recall: {res[2]:.4f}, F1: {res[3]:.4f}, ROC AUC: {res[4]:.4f}, AUCPR: {res[5]:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Scenario 4: Hyperparameter Tuning**\n\n**Tune:**\n\n* n_estimators âˆˆ {10, 25, 50, 100, 150, 200}\n* max_samples âˆˆ {64, 128, 256, 512, 1024}\n* contamination âˆˆ {0.0004, 0.0008, 0.001, 0.0015, 0.002}\n","metadata":{}},{"cell_type":"code","source":"params_grid = list(product([100, 150, 200], [64, 128, 256], [0.0004, 0.0008, 0.001, 0.0015]))\nscenario4_results = []\n\nfor n_est, max_samp, contam in params_grid:\n    model = IsolationForest(n_estimators=n_est, max_samples=max_samp, contamination=contam, random_state=42)\n    model.fit(X_train_combined)\n    y_pred = model.predict(X_test)\n    y_pred = [1 if x == -1 else 0 for x in y_pred]\n\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n    roc = roc_auc_score(y_test, y_pred)\n    precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_pred)\n    aucpr = auc(recall_vals, precision_vals)\n\n    scenario4_results.append(((n_est, max_samp, contam), precision, recall, f1, roc, aucpr))\n\nscenario4_results.sort(key=lambda x: x[3], reverse=True)\nprint(\"Top 5 configurations by F1-score:\")\nfor res in scenario4_results[:5]:\n    print(f\"Params: Trees={res[0][0]}, MaxSamples={res[0][1]}, Contam={res[0][2]} | Precision={res[1]:.4f}, Recall={res[2]:.4f}, F1={res[3]:.4f}, ROC={res[4]:.4f}, AUCPR={res[5]:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Interpretability and Explainability methods**","metadata":{}},{"cell_type":"code","source":"lime_exp = lime.lime_tabular.LimeTabularExplainer(\n    training_data=np.array(X_train_combined),\n    feature_names=X_df.columns,\n    mode='classification',\n    class_names=[\"Normal\", \"Fraud\"]\n)\n\nidx = 10\nexp = lime_exp.explain_instance(X_test[idx], model.predict, num_features=5)\nexp.show_in_notebook()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T11:59:58.198330Z","iopub.status.idle":"2025-05-01T11:59:58.198880Z","shell.execute_reply.started":"2025-05-01T11:59:58.198531Z","shell.execute_reply":"2025-05-01T11:59:58.198548Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Isolation Forest Built-in Feature Importances**","metadata":{}},{"cell_type":"code","source":"importances = model.feature_importances_\nplt.barh(X_df.columns, importances)\nplt.title(\"Isolation Forest Feature Importances\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T11:59:58.200093Z","iopub.status.idle":"2025-05-01T11:59:58.200515Z","shell.execute_reply.started":"2025-05-01T11:59:58.200314Z","shell.execute_reply":"2025-05-01T11:59:58.200331Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Autoencoder Feature Agreement**","metadata":{}},{"cell_type":"code","source":"input_dim = X_train_combined.shape[1]\ninput_layer = Input(shape=(input_dim,))\nencoder = Dense(32, activation=\"relu\")(input_layer)\nencoder = Dense(16, activation=\"relu\")(encoder)\ndecoder = Dense(input_dim, activation=\"linear\")(encoder)\nautoencoder = Model(input_layer, decoder)\nautoencoder.compile(optimizer=Adam(), loss=\"mse\")\nautoencoder.fit(X_train_combined, X_train_combined, epochs=10, batch_size=256, verbose=1)\n\nreconstructions = autoencoder.predict(X_test)\nmse = np.mean(np.square(X_test - reconstructions), axis=1)\n\nthreshold = np.percentile(mse, 95)\nanomalies_auto = (mse > threshold).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T11:59:58.202746Z","iopub.status.idle":"2025-05-01T11:59:58.203183Z","shell.execute_reply.started":"2025-05-01T11:59:58.202922Z","shell.execute_reply":"2025-05-01T11:59:58.202936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(confusion_matrix(y_pred, anomalies_auto))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T11:59:58.203830Z","iopub.status.idle":"2025-05-01T11:59:58.204280Z","shell.execute_reply.started":"2025-05-01T11:59:58.204065Z","shell.execute_reply":"2025-05-01T11:59:58.204079Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **SHAP**","metadata":{}},{"cell_type":"code","source":"explainer = shap.Explainer(model.predict, X_test[:100]) \nshap_values = explainer(X_test[:10])\n\nshap.summary_plot(shap_values, X_test[:10], feature_names=X_df.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T11:59:58.205686Z","iopub.status.idle":"2025-05-01T11:59:58.206045Z","shell.execute_reply.started":"2025-05-01T11:59:58.205843Z","shell.execute_reply":"2025-05-01T11:59:58.205855Z"}},"outputs":[],"execution_count":null}]}